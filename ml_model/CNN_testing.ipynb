{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyNHj9nNwZmIL2nPPyzui13W"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"WSiphATR7qzZ","executionInfo":{"status":"ok","timestamp":1754092222550,"user_tz":-330,"elapsed":29553,"user":{"displayName":"Shagun Thakur","userId":"13424547828332525299"}},"outputId":"c6a0b62d-6c41-463b-bd5b-328ce11d9587"},"execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}]},{"cell_type":"markdown","source":["Preprocessing of the audios"],"metadata":{"id":"v_NIk4wb5GgW"}},{"cell_type":"code","source":["# converting file from .acc to 16 kHz mono .wav file\n","from pydub import AudioSegment\n","\n","def convert_aac_to_wav(input_path, output_path, target_sr=16000):\n","    \"\"\"\n","    Converts a .aac audio file to a 16 kHz mono .wav file.\n","\n","    Args:\n","        input_path (str): Path to input .aac file\n","        output_path (str): Path to save output .wav file\n","        target_sr (int): Target sample rate (default 16,000 Hz)\n","\n","    Returns:\n","        str: Path to the saved .wav file\n","    \"\"\"\n","\n","    # Load AAC file\n","    audio = AudioSegment.from_file(input_path, format=\"aac\")\n","\n","    # Set frame rate (sampling rate), and convert to mono\n","    audio = audio.set_frame_rate(target_sr).set_channels(1)\n","\n","    # Export as WAV\n","    audio.export(output_path, format=\"wav\")\n","\n","    return output_path\n"],"metadata":{"id":"sePkWdeFBJX_","executionInfo":{"status":"ok","timestamp":1754092233108,"user_tz":-330,"elapsed":718,"user":{"displayName":"Shagun Thakur","userId":"13424547828332525299"}}},"execution_count":2,"outputs":[]},{"cell_type":"code","source":["acc_file = \"/content/drive/MyDrive/31 Jul, 12.42 pm​.aac\"\n","wav_file = \"/content/drive/MyDrive/CNN_test_file1.wav\"\n","converted = convert_aac_to_wav(acc_file, wav_file)\n","print(f\"Saved WAV at: {converted}\")\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"HtdRhS0oBmtN","executionInfo":{"status":"ok","timestamp":1754092426178,"user_tz":-330,"elapsed":660,"user":{"displayName":"Shagun Thakur","userId":"13424547828332525299"}},"outputId":"090b1d0f-d3a3-4817-bbd7-a5f791009a6e"},"execution_count":5,"outputs":[{"output_type":"stream","name":"stdout","text":["Saved WAV at: /content/drive/MyDrive/CNN_test_file1.wav\n"]}]},{"cell_type":"code","execution_count":6,"metadata":{"id":"O4z__eqt48sQ","executionInfo":{"status":"ok","timestamp":1754092435083,"user_tz":-330,"elapsed":449,"user":{"displayName":"Shagun Thakur","userId":"13424547828332525299"}}},"outputs":[],"source":["# Extracting the mel-spectrogram\n","import librosa\n","import numpy as np\n","\n","def extract_fixed_length_melspectrogram(\n","        file_path,\n","        sr=16000,\n","        n_mels=40,\n","        n_fft=512,\n","        hop_length=256,\n","        duration=2.0  # seconds\n","    ):\n","    \"\"\"\n","    Extract a fixed-length mel-spectrogram in decibels from an audio file.\n","\n","    Args:\n","        file_path (str): Path to WAV audio file.\n","        sr (int): Sampling rate to load audio.\n","        n_mels (int): Number of mel bands.\n","        n_fft (int): FFT window size.\n","        hop_length (int): Samples between successive frames.\n","        duration (float): Duration in seconds to which audio is trimmed/padded.\n","\n","    Returns:\n","        np.ndarray: Mel-spectrogram in shape (n_mels, time_frames) as float32.\n","    \"\"\"\n","\n","    # Load audio, trim/pad to fixed length\n","    samples = int(sr * duration)\n","    y, _ = librosa.load(file_path, sr=sr, mono=True, duration=duration)\n","\n","    # Pad with zeros if shorter than duration\n","    if len(y) < samples:\n","        padding = samples - len(y)\n","        y = np.pad(y, (0, padding), mode='constant')\n","\n","    # Or truncate if longer\n","    else:\n","        y = y[:samples]\n","\n","    # Compute mel spectrogram (power)\n","    mel_spec = librosa.feature.melspectrogram(\n","        y=y,\n","        sr=sr,\n","        n_fft=n_fft,\n","        hop_length=hop_length,\n","        n_mels=n_mels,\n","        power=2.0\n","    )\n","\n","    # Convert to log scale (dB)\n","    mel_spec_db = librosa.power_to_db(mel_spec, ref=np.max)\n","\n","    return mel_spec_db.astype(np.float32)\n"]},{"cell_type":"code","source":["import numpy as np\n","\n","def crop_or_pad_melspectrogram(mel_spec, target_shape=(40, 63)):\n","    \"\"\"\n","    Crop or pad mel-spectrogram to the target shape.\n","\n","    Args:\n","        mel_spec (np.ndarray): Mel-spectrogram array with shape (n_mels, time_frames)\n","        target_shape (tuple): Desired shape (n_mels, time_frames), e.g. (40, 63)\n","\n","    Returns:\n","        np.ndarray: Mel-spectrogram cropped/padded to target shape\n","    \"\"\"\n","\n","    n_mels, time_frames = mel_spec.shape\n","    target_mels, target_frames = target_shape\n","\n","    # Crop mel bins if needed (usually equal)\n","    if n_mels > target_mels:\n","        mel_spec = mel_spec[:target_mels, :]\n","    elif n_mels < target_mels:\n","        pad_width = target_mels - n_mels\n","        mel_spec = np.pad(mel_spec, ((0, pad_width), (0, 0)), mode='constant')\n","\n","    # Crop or pad time frames dimension\n","    if time_frames > target_frames:\n","        mel_spec = mel_spec[:, :target_frames]\n","    elif time_frames < target_frames:\n","        pad_width = target_frames - time_frames\n","        mel_spec = np.pad(mel_spec, ((0, 0), (0, pad_width)), mode='constant')\n","\n","    return mel_spec\n"],"metadata":{"id":"xJaS5YVM5nSA","executionInfo":{"status":"ok","timestamp":1754092442725,"user_tz":-330,"elapsed":432,"user":{"displayName":"Shagun Thakur","userId":"13424547828332525299"}}},"execution_count":7,"outputs":[]},{"cell_type":"code","source":["from tensorflow.keras.models import load_model"],"metadata":{"id":"uolaWlrO7eAb","executionInfo":{"status":"ok","timestamp":1754092494262,"user_tz":-330,"elapsed":447,"user":{"displayName":"Shagun Thakur","userId":"13424547828332525299"}}},"execution_count":9,"outputs":[]},{"cell_type":"code","source":["model = load_model('/content/drive/MyDrive/cnn_audio_classifier_approach (1).h5')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"y5mQM99K72Wi","executionInfo":{"status":"ok","timestamp":1754092503166,"user_tz":-330,"elapsed":426,"user":{"displayName":"Shagun Thakur","userId":"13424547828332525299"}},"outputId":"a242b0ee-069d-4858-a96b-8c7913cd3743"},"execution_count":10,"outputs":[{"output_type":"stream","name":"stderr","text":["WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"]}]},{"cell_type":"code","source":["# Preprocessing a single audio file\n","file_path = \"/content/drive/MyDrive/CNN_test_file1.wav\"\n","\n","mel_spec = extract_fixed_length_melspectrogram(file_path)\n","mel_spec = crop_or_pad_melspectrogram(mel_spec, target_shape=(40, 63))\n"],"metadata":{"id":"NUS75iE_8dQa","executionInfo":{"status":"ok","timestamp":1754092541223,"user_tz":-330,"elapsed":17872,"user":{"displayName":"Shagun Thakur","userId":"13424547828332525299"}}},"execution_count":11,"outputs":[]},{"cell_type":"code","source":["# ---- Prepare for model input: reshape to (1, 40, 63, 1) ----\n","input_data = np.expand_dims(mel_spec, axis=(0, -1))  # shape becomes (1, 40, 63, 1)\n"],"metadata":{"id":"zkoCs5xQ8sxK","executionInfo":{"status":"ok","timestamp":1754092543934,"user_tz":-330,"elapsed":671,"user":{"displayName":"Shagun Thakur","userId":"13424547828332525299"}}},"execution_count":12,"outputs":[]},{"cell_type":"markdown","source":["**-------------------------------------------------Testing of cnn_audio_classifier_approach (1).h5-------------------------------------------------------**"],"metadata":{"id":"dLr-3A1fFheQ"}},{"cell_type":"code","source":["# prediction\n","prediction = model.predict(input_data)\n","print(\"Raw prediction:\", prediction)\n","threshold = 0.5\n","predicted_class = int(prediction[0][0] >= threshold)\n","\n","# Optional: Human-readable label\n","class_labels = ['non-emergency', 'emergency']\n","print(\"Predicted class:\", predicted_class)\n","print(\"Predicted label:\", class_labels[predicted_class])\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"IaJXs1Lm8-uG","executionInfo":{"status":"ok","timestamp":1754092663642,"user_tz":-330,"elapsed":514,"user":{"displayName":"Shagun Thakur","userId":"13424547828332525299"}},"outputId":"cb9d2225-0a29-403f-9c6d-af4aa63f466f"},"execution_count":14,"outputs":[{"output_type":"stream","name":"stdout","text":["\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step\n","Raw prediction: [[0.21432546]]\n","Predicted class: 0\n","Predicted label: non-emergency\n"]}]},{"cell_type":"markdown","source":["**--------------------------------------------------Testing of cnn_with_preprocessing_2.h5---------------------------------------------------**"],"metadata":{"id":"Q4FjdDO2EvWd"}},{"cell_type":"code","source":["# Due to STFTLayer\n","custom_objects = {\n","    'STFTLayer': STFTLayer,\n","    'MelSpectrogramLayer': MelSpectrogramLayer,\n","    'LogScaleLayer': LogScaleLayer,\n","    'ExpandDimsLayer': ExpandDimsLayer,\n","    'CroppingTimeLayer': CroppingTimeLayer,\n","    'TransposeLayer': TransposeLayer\n","}\n","\n","model = load_model(\"cnn_with_preprocessing_2.h5\", custom_objects=custom_objects)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":219},"id":"ytv9aldgEu4u","executionInfo":{"status":"error","timestamp":1754093539089,"user_tz":-330,"elapsed":759,"user":{"displayName":"Shagun Thakur","userId":"13424547828332525299"}},"outputId":"98d0f167-263b-4ac3-b59d-4b70d022191e"},"execution_count":16,"outputs":[{"output_type":"error","ename":"NameError","evalue":"name 'STFTLayer' is not defined","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m/tmp/ipython-input-2097946687.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Due to STFTLayer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m custom_objects = {\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0;34m'STFTLayer'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mSTFTLayer\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m     \u001b[0;34m'MelSpectrogramLayer'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mMelSpectrogramLayer\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0;34m'LogScaleLayer'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mLogScaleLayer\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mNameError\u001b[0m: name 'STFTLayer' is not defined"]}]},{"cell_type":"code","source":["# prediction\n","prediction = preprocessed_model.predict(input_data)\n","print(\"Raw prediction:\", prediction)\n","threshold = 0.5\n","predicted_class = int(prediction[0][0] >= threshold)\n","\n","# Optional: Human-readable label\n","class_labels = ['non-emergency', 'emergency']\n","print(\"Predicted class:\", predicted_class)\n","print(\"Predicted label:\", class_labels[predicted_class])"],"metadata":{"id":"g5sSpID4ECjr"},"execution_count":null,"outputs":[]}]}